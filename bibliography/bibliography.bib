 @article{healthcare, 
 title={Reinforcement Learning in Healthcare: A Survey}, 
 url={https://arxiv.org/abs/1908.08796}, 
 journal={arXiv.org}, 
 author={Yu, Chao and Liu, Jiming and Nemati, Shamim}, 
 year={2020}, 
 month={Apr}} 
 
 @misc{horizon, 
 title={Horizon: An open-source reinforcement learning platform},
 url={https://engineering.fb.com/2018/11/01/ml-applications/horizon/}, 
 journal={Facebook Engineering}, 
 author={Gauci, Jason and Gauci, Jason and Conti, Edoardo and Virochsiri, Kittipat}, 
 year={2020}, 
 month={Mar}} 
 
 @misc{roboticManipulation, 
 title={Scalable Deep Reinforcement Learning for Robotic Manipulation}, 
 url={https://ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html}, 
 journal={Google AI Blog}, 
 year={2018}, 
 month={Jun}} 
  
 @misc{datacentre, 
 title={Safety-first AI for autonomous data centre cooling and industrial control}, 
 url={https://deepmind.com/blog/article/safety-first-ai-autonomous-data-centre-cooling-and-industrial-control}, 
 journal={Deepmind}}
 
 @article{autonomousDriving,
 title={Deep Reinforcement Learning for Autonomous Driving: A Survey},
 url={https://arxiv.org/pdf/2002.00444.pdf},
 journal={arXiv.org}, 
 author={B Kiran, Ravi and Sobh, Ibrahim and Talpaert Victor and Mannion, Patrick and Al Sallab, Ahmad A. and Yogamani, Senthil and PÃ©rez, Patrick},
 year={2020},
 month={Feb}
 }
 
 @misc{NLP,
 title={A deep reinforced model for abstractive summarization},
 url={https://arxiv.org/pdf/1705.04304.pdf},
 journal={arXiv.org},
 author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
 year={2017},
 month={November}}
  
 @article{SDNSynchronisation, 
 title={DQ Scheduler: Deep Reinforcement Learning Based Controller Synchronization in Distributed SDN}, 
 DOI={10.1109/icc.2019.8761183}, 
 journal={ICC 2019 - 2019 IEEE International Conference on Communications (ICC)}, 
 author={Zhang, Ziyao and Ma, Liang and Poularakis, Konstantinos and Leung, Kin K. and Wu, Lingfei}, 
 year={2019}} 

 @article{ServicePlacement, 
 title={Q-Placement: Reinforcement-Learning-Based Service Placement in Software-Defined  Networks}, 
 DOI={10.1109/icdcs.2018.00159}, 
 journal={2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)}, 
 author={Zhang, Ziyao and Ma, Liang and Leung, Kin K. and Tassiulas, Leandros and Tucker, Jeremy}, 
 year={2018}} 

 @book{sutton_barto_2018, 
 place={Cambridge, MA}, 
 title={Reinforcement learning: an introduction}, 
 publisher={The MIT Press}, 
 author={Sutton, Richard S. and Barto, Andrew G.}, 
 year={2018},
 pages={352}} 

 @phdthesis{watkins_1989, 
 title={Learning from delayed rewards}, 
 author={Watkins, Christopher John Cornish Hellaby.}, 
 school={University of Cambridge},
 year={1989}}

 @ARTICLE{dqn,
       author = {{Mnih}, Volodymyr and {Kavukcuoglu}, Koray and {Silver}, David and {Graves}, Alex and {Antonoglou}, Ioannis and {Wierstra}, Daan and {Riedmiller}, Martin},
        title = "{Playing Atari with Deep Reinforcement Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning},
         year = 2013,
        month = dec,
          eid = {arXiv:1312.5602},
        pages = {arXiv:1312.5602},
 archivePrefix = {arXiv},
       eprint = {1312.5602},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2013arXiv1312.5602M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
 }

 @ARTICLE{stateActionEmbeddings,
       author = {{Pritz}, Paul J. and {Ma}, Liang and {Leung}, Kin K.},
        title = "{Jointly-Trained State-Action Embedding for Efficient Reinforcement Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2020,
        month = oct,
          eid = {arXiv:2010.04444},
        pages = {arXiv:2010.04444},
 archivePrefix = {arXiv},
       eprint = {2010.04444},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201004444P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
 }

 @ARTICLE{worldModels,
       author = {{Ha}, David and {Schmidhuber}, J{\"u}rgen},
        title = "{World Models}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2018,
        month = mar,
          eid = {arXiv:1803.10122},
        pages = {arXiv:1803.10122},
 archivePrefix = {arXiv},
       eprint = {1803.10122},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180310122H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
 }

 @ARTICLE{stateAggregation,
       author = {{Dean}, Thomas L. and {Givan}, Robert and {Leach}, Sonia},
        title = "{Model Reduction Techniques for Computing Approximately Optimal Solutions for Markov Decision Processes}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence},
         year = 2013,
        month = feb,
          eid = {arXiv:1302.1533},
        pages = {arXiv:1302.1533},
 archivePrefix = {arXiv},
       eprint = {1302.1533},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2013arXiv1302.1533D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
 }

 @ARTICLE{aggregationHierarchical,
 title={State Space Reduction For Hierarchical Reinforcement Learning},
 author={Asadi, Mehran and Huber, Manfred},
 url={http://ranger.uta.edu/~huber/papers/FLAIRS04AsadiM.pdf},
 year=2004}}

 @ARTICLE{2016arXiv160601540B,
       author = {{Brockman}, Greg and {Cheung}, Vicki and {Pettersson}, Ludwig and {Schneider}, Jonas and {Schulman}, John and {Tang}, Jie and {Zaremba}, Wojciech},
        title = "{OpenAI Gym}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2016,
        month = jun,
          eid = {arXiv:1606.01540},
        pages = {arXiv:1606.01540},
 archivePrefix = {arXiv},
       eprint = {1606.01540},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160601540B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
 }

 @misc{cartpole, 
 title={A toolkit for developing and comparing reinforcement learning algorithms}, 
 url={https://gym.openai.com/envs/CartPole-v1/}, 
 journal={Gym}, 
 author={OpenAI},
 note = {Accessed: 2021-01-23}} 
 
 @misc{keras, 
 title={Simple. Flexible. Powerful.}, 
 url={https://keras.io/}, 
 journal={Keras}, 
 author={Team, Keras},
 note = {Accessed: 2021-01-23}}

  