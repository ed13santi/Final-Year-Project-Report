\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{sutton_barto_2018}
\citation{silver_mastering_2017}
\citation{yu_reinforcement_2020}
\citation{noauthor_google_nodate}
\citation{autonomousDriving}
\citation{NLP}
\citation{ServicePlacement}
\citation{SDNSynchronisation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.5}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{yu_reinforcement_2020}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{noauthor_google_nodate}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{autonomousDriving}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{NLP}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{ServicePlacement}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{SDNSynchronisation}{{2}{1.1}{section*.5}}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Definition}{2}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure of the report}{2}{section.10}\protected@file@percent }
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{3}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.13}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{3}{2.1}{section*.13}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction of the agent with the environment during time step $t$. Figure taken from \cite  {sutton_barto_2018}\relax }}{3}{figure.caption.14}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{3}{2.1}{figure.caption.14}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agent-env-interaction}{{2.1}{3}{Interaction of the agent with the environment during time step $t$. Figure taken from \cite {sutton_barto_2018}\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.18}\protected@file@percent }
\citation{noauthor_markov_2021}
\citation{noauthor_markov_2021}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite  {noauthor_markov_2021}\relax }}{4}{figure.caption.25}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_markov_2021}{{4}{2.2}{figure.caption.25}}}
\newlabel{fig:MDP}{{2.2}{4}{Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite {noauthor_markov_2021}\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.26}\protected@file@percent }
\citation{bellman_dynamic_1966}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.41}\protected@file@percent }
\@writefile{brf}{\backcite{bellman_dynamic_1966}{{5}{2.1}{section*.41}}}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.44}\protected@file@percent }
\citation{watkins_1989}
\citation{watkins_q-learning_1992}
\citation{mnih_human-level_2015}
\citation{dqn}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural networks}{6}{section.48}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Q-learning and Deep Q-learning}{6}{section.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.50}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_1989}{{6}{2.3}{section*.50}}}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.53}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_q-learning_1992}{{6}{2.3}{section*.53}}}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.54}\protected@file@percent }
\@writefile{brf}{\backcite{mnih_human-level_2015}{{6}{2.3}{section*.54}}}
\@writefile{brf}{\backcite{dqn}{{6}{2.3}{section*.54}}}
\citation{wiskunde_doubleq-learning_nodate}
\citation{van_hasselt_deep_2015}
\citation{wang_dueling_nodate}
\citation{goos_q-learning_1999}
\citation{dqn}
\citation{stateActionEmbeddings}
\citation{worldModels}
\citation{stateAggregation}
\citation{aggregationHierarchical}
\citation{barto_recent_2003}
\citation{dietterich_hierarchical_1999}
\citation{sutton_between_1999}
\citation{parr_reinforcement_nodate}
\citation{moerland_model-based_2020}
\citation{sutton_dyna_1991}
\citation{silver_mastering_2017}
\citation{worldModels}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.56}\protected@file@percent }
\@writefile{brf}{\backcite{wiskunde_doubleq-learning_nodate}{{7}{2.3}{section*.56}}}
\@writefile{brf}{\backcite{van_hasselt_deep_2015}{{7}{2.3}{section*.56}}}
\@writefile{brf}{\backcite{wang_dueling_nodate}{{7}{2.3}{section*.56}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.58}\protected@file@percent }
\@writefile{brf}{\backcite{goos_q-learning_1999}{{7}{2.3}{section*.58}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem of large state-spaces}{7}{section.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.61}\protected@file@percent }
\@writefile{brf}{\backcite{dqn}{{7}{2.4}{section*.61}}}
\@writefile{brf}{\backcite{stateActionEmbeddings}{{7}{2.4}{section*.61}}}
\@writefile{brf}{\backcite{worldModels}{{7}{2.4}{section*.61}}}
\@writefile{brf}{\backcite{stateAggregation}{{7}{2.4}{section*.61}}}
\@writefile{brf}{\backcite{aggregationHierarchical}{{7}{2.4}{section*.61}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.62}\protected@file@percent }
\@writefile{brf}{\backcite{barto_recent_2003}{{7}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{dietterich_hierarchical_1999}{{7}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{sutton_between_1999}{{7}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{parr_reinforcement_nodate}{{7}{2.4}{section*.62}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.63}\protected@file@percent }
\@writefile{brf}{\backcite{moerland_model-based_2020}{{7}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{sutton_dyna_1991}{{8}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{8}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{worldModels}{{8}{2.4}{section*.63}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}State-Decomposition method}{9}{chapter.65}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}State-Decomposition method}{9}{section.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.68}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }}{9}{figure.caption.70}\protected@file@percent }
\newlabel{fig:OneMDPtoManyMDPs}{{3.1}{9}{Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }{figure.caption.70}{}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.73}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }}{10}{figure.caption.75}\protected@file@percent }
\newlabel{fig:join_nets}{{3.2}{10}{The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Decomposing state trans. matrix}{11}{subsection.78}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.79}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces State-decomposition algorithm.\relax }}{11}{algocf.81}\protected@file@percent }
\newlabel{algo:decompose}{{1}{11}{}{algocf.81}{}}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.82}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces State-decomposition into given number of sub-spaces\relax }}{12}{algocf.84}\protected@file@percent }
\newlabel{algo:threshold}{{2}{12}{}{algocf.84}{}}
\citation{noauthor_cloud_nodate}
\citation{keras}
\citation{noauthor_tensorflow_nodate}
\citation{openai_gym_nodate}
\citation{noauthor_openai_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Design and testing of the proposed decomposition technique}{13}{chapter.85}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Tools}{13}{section.87}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Python}{13}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Google Colaboratory}{13}{section*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Keras}{13}{section*.91}\protected@file@percent }
\@writefile{brf}{\backcite{keras}{{13}{4.1}{section*.91}}}
\@writefile{brf}{\backcite{noauthor_tensorflow_nodate}{{13}{4.1}{section*.91}}}
\@writefile{toc}{\contentsline {paragraph}{OpenAI Gym}{13}{section*.92}\protected@file@percent }
\@writefile{brf}{\backcite{openai_gym_nodate}{{13}{4.1}{section*.92}}}
\@writefile{brf}{\backcite{noauthor_cloud_nodate}{{13}{1}{section*.89}}}
\citation{noauthor_openai_nodate}
\citation{noauthor_openai_nodate}
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{14}{4.1}{section*.92}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite  {noauthor_openai_nodate}\relax }}{14}{figure.caption.93}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{14}{4.1}{figure.caption.93}}}
\newlabel{fig:cartpole}{{4.1}{14}{The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite {noauthor_openai_nodate}\relax }{figure.caption.93}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Obtaining the state trans. matrix}{14}{subsection.94}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.95}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}The need for a suitable environment}{14}{section.96}\protected@file@percent }
\newlabel{sec:TaxiTraps}{{4.2}{14}{The need for a suitable environment}{section.96}{}}
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.99}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.100}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces On the left, the original "Taxi" environment. On the right, the "TaxiTraps" environment.\relax }}{16}{figure.caption.104}\protected@file@percent }
\newlabel{fig:taxi}{{4.2}{16}{On the left, the original "Taxi" environment. On the right, the "TaxiTraps" environment.\relax }{figure.caption.104}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {"Taxi"}}}{16}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {"TaxiTraps"}}}{16}{subfigure.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces State transition probabilities in the 'GridEps' environment.\relax }}{16}{table.caption.107}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 'Grid' environment. The dotted lines have no effect on the environment, they are just used to separate what will be referred to as the uppper-left triangle and the lower-right triangle.\relax }}{17}{figure.caption.108}\protected@file@percent }
\newlabel{fig:grid}{{4.3}{17}{'Grid' environment. The dotted lines have no effect on the environment, they are just used to separate what will be referred to as the uppper-left triangle and the lower-right triangle.\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Implementation of the DQN agents}{17}{section.109}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Benchmark DQN agent}{17}{section.110}\protected@file@percent }
\citation{kingma_adam_2017}
\@writefile{brf}{\backcite{kingma_adam_2017}{{18}{4.4}{section.110}}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Ensuring fair comparison}{18}{section.113}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{19}{chapter.114}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation method}{19}{section.115}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Effect of different state representations on the performance}{19}{section.116}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Effect of different state encoding methods on the performance of DeltaSwitch. IN WCHIH ENVIRONMENT??? SHOULD SHOW FOR DQN INSTEAD\relax }}{20}{figure.caption.121}\protected@file@percent }
\newlabel{fig:effect-state-encoding}{{5.1}{20}{Effect of different state encoding methods on the performance of DeltaSwitch. IN WCHIH ENVIRONMENT??? SHOULD SHOW FOR DQN INSTEAD\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}First approach}{20}{section.122}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Initial results with Taxi2 and original state decomposition algorithm}{20}{section.123}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Effect of varying the neural network's size}{20}{section.124}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }}{21}{figure.caption.125}\protected@file@percent }
\newlabel{fig:effect_NN_dimension}{{5.2}{21}{Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }{figure.caption.125}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}A simple approach to decomposition: 'DeltaSwitch'}{21}{section.126}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Combining 'NN0' and 'NN1' using another NN.\relax }}{22}{figure.caption.128}\protected@file@percent }
\newlabel{fig:combined-network}{{5.3}{22}{Combining 'NN0' and 'NN1' using another NN.\relax }{figure.caption.128}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Taxi2 environment.\relax }}{22}{figure.caption.129}\protected@file@percent }
\newlabel{fig:Taxi2-dqn-deltaSwitch}{{5.4}{22}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Taxi2 environment.\relax }{figure.caption.129}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }}{23}{figure.caption.130}\protected@file@percent }
\newlabel{fig:gridNoWall-dqn-deltaSwitch}{{5.5}{23}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }{figure.caption.130}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Comparison of DeltaSwitch with different $\delta $.\relax }}{24}{figure.caption.131}\protected@file@percent }
\newlabel{fig:gridNoWall-deltaSwitch-compareDelta}{{5.6}{24}{Comparison of DeltaSwitch with different $\delta $.\relax }{figure.caption.131}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Effect of using reduced encoding}{24}{section.132}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Effect of reducing the input size.\relax }}{25}{figure.caption.133}\protected@file@percent }
\newlabel{fig:reduced-effect}{{5.7}{25}{Effect of reducing the input size.\relax }{figure.caption.133}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Samples plots}{25}{section.134}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.9}Effect of wall / no wall}{25}{section.135}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }}{26}{figure.caption.136}\protected@file@percent }
\newlabel{fig:wall}{{5.8}{26}{Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }{figure.caption.136}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.10}Effect of decomposing by destination or by position}{26}{section.137}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }}{27}{figure.caption.138}\protected@file@percent }
\newlabel{fig:one-hot}{{5.9}{27}{Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }{figure.caption.138}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.11}A different approach based on transfer learning}{27}{section.139}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \tmspace  +\thickmuskip {.2777em}1\%$.\relax }}{28}{figure.caption.140}\protected@file@percent }
\newlabel{fig:learnSwitch1}{{5.10}{28}{Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \;1\%$.\relax }{figure.caption.140}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }}{29}{figure.caption.142}\protected@file@percent }
\newlabel{fig:initialisedLearnSwitch}{{5.11}{29}{Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }{figure.caption.142}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }}{29}{figure.caption.145}\protected@file@percent }
\newlabel{fig:SARSA-progressive}{{5.12}{29}{Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }{figure.caption.145}{}}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\@writefile{brf}{\backcite{rusu_progressive_2016}{{30}{5.11}{figure.caption.145}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Structure of progressive network when training the third task. Figure taken from \cite  {rusu_progressive_2016}.\relax }}{30}{figure.caption.146}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{30}{5.13}{figure.caption.146}}}
\newlabel{fig:progressive-3-tasks}{{5.13}{30}{Structure of progressive network when training the third task. Figure taken from \cite {rusu_progressive_2016}.\relax }{figure.caption.146}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.12}Techniques to learn the 'switch'}{30}{section.147}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }}{31}{figure.caption.150}\protected@file@percent }
\newlabel{fig:progressive-combining-simultaneous}{{5.14}{31}{Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }{figure.caption.150}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the comining network itself. $h$ indicates hidden layers of the network.\relax }}{32}{figure.caption.151}\protected@file@percent }
\newlabel{fig:modified-progressive}{{5.15}{32}{Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the comining network itself. $h$ indicates hidden layers of the network.\relax }{figure.caption.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.13}Can have separate subsection for things that didn't work}{32}{section.152}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Applicability of the proposed technique}{34}{chapter.153}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.154}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.155}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Allocation of resources problem for two interconnected data centres.\relax }}{34}{figure.caption.156}\protected@file@percent }
\newlabel{fig:data-centres}{{6.1}{34}{Allocation of resources problem for two interconnected data centres.\relax }{figure.caption.156}{}}
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.157}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.158}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.159}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Possible state-decomposition agent.\relax }}{36}{figure.caption.160}\protected@file@percent }
\newlabel{fig:data-centres-decomposition-agent}{{6.2}{36}{Possible state-decomposition agent.\relax }{figure.caption.160}{}}
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.161}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions and Further Work}{37}{chapter.162}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Extensions}{37}{section.163}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Compression and embeddings of states}{37}{section*.164}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to continuous state-spaces}{37}{section*.165}\protected@file@percent }
\citation{simsek_identifying_2005}
\citation{menache_q-cutdynamic_2002}
\@writefile{toc}{\contentsline {paragraph}{Applying threshold to transitions between whole sub-spaces}{38}{section*.166}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Offline training}{38}{section*.167}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sharing information between sub-agents}{38}{section*.168}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }}{38}{figure.caption.169}\protected@file@percent }
\newlabel{fig:connected-states}{{7.1}{38}{MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }{figure.caption.169}{}}
\@writefile{toc}{\contentsline {paragraph}{Using state-decomposition for automatic sub-goal discovery}{38}{section*.170}\protected@file@percent }
\@writefile{brf}{\backcite{simsek_identifying_2005}{{38}{7.1}{section*.170}}}
\@writefile{brf}{\backcite{menache_q-cutdynamic_2002}{{38}{7.1}{section*.170}}}
\bibstyle{plain}
\bibdata{bibliography/bibliography,bibliography/zotero}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Applications}{39}{subsection.171}\protected@file@percent }
\bibcite{noauthor_cloud_nodate}{1}
\bibcite{noauthor_google_nodate}{2}
\bibcite{noauthor_markov_2021}{3}
\bibcite{noauthor_openai_nodate}{4}
\bibcite{noauthor_tensorflow_nodate}{5}
\bibcite{aggregationHierarchical}{6}
\bibcite{autonomousDriving}{7}
\bibcite{barto_recent_2003}{8}
\bibcite{bellman_dynamic_1966}{9}
\bibcite{stateAggregation}{10}
\bibcite{dietterich_hierarchical_1999}{11}
\bibcite{goos_q-learning_1999}{12}
\bibcite{worldModels}{13}
\bibcite{kingma_adam_2017}{14}
\bibcite{menache_q-cutdynamic_2002}{15}
\bibcite{dqn}{16}
\bibcite{mnih_human-level_2015}{17}
\bibcite{moerland_model-based_2020}{18}
\bibcite{openai_gym_nodate}{19}
\bibcite{parr_reinforcement_nodate}{20}
\bibcite{NLP}{21}
\bibcite{stateActionEmbeddings}{22}
\bibcite{rusu_progressive_2016}{23}
\bibcite{silver_mastering_2017}{24}
\bibcite{sutton_dyna_1991}{25}
\bibcite{sutton_barto_2018}{26}
\bibcite{sutton_between_1999}{27}
\bibcite{keras}{28}
\bibcite{van_hasselt_deep_2015}{29}
\bibcite{wang_dueling_nodate}{30}
\bibcite{watkins_q-learning_1992}{31}
\bibcite{watkins_1989}{32}
\bibcite{wiskunde_doubleq-learning_nodate}{33}
\bibcite{yu_reinforcement_2020}{34}
\bibcite{ServicePlacement}{35}
\bibcite{SDNSynchronisation}{36}
\bibcite{simsek_identifying_2005}{37}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Code}{43}{appendix.173}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{43}{Code}{appendix.173}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.1}Function which is given the state-transition matrix in input and combines the thresholding of its values with the decomposition into separate MDPs, returning \texttt  {d} which is a list indicating which sub-space each state belongs to (as an index) and \texttt  {groups} which is a list of lists containing the states of each sub-space.}{43}{lstlisting.175}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.2}Function that given the state-transition and a target number of subspaces performs the state-decomposition with different thresholds in order to obtain the correct number of sub-spaces.}{43}{lstlisting.197}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.3}Current version of my state-decomposition agent. In this version the states are fed in the neural networks as one-hot-encoded integers.}{44}{lstlisting.222}\protected@file@percent }
