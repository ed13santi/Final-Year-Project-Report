\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{sutton_barto_2018}
\citation{silver_mastering_2017}
\citation{yu_reinforcement_2020}
\citation{noauthor_google_nodate}
\citation{autonomousDriving}
\citation{NLP}
\citation{ServicePlacement}
\citation{SDNSynchronisation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.5}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{yu_reinforcement_2020}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{noauthor_google_nodate}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{autonomousDriving}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{NLP}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{ServicePlacement}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{SDNSynchronisation}{{2}{1.1}{section*.5}}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Definition}{2}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure of the report}{3}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.11}\protected@file@percent }
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{4}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{4}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.14}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{section*.14}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction of the agent with the environment during time step $t$. Figure taken from \cite  {sutton_barto_2018}\relax }}{4}{figure.caption.15}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{figure.caption.15}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agent-env-interaction}{{2.1}{4}{Interaction of the agent with the environment during time step $t$. Figure taken from \cite {sutton_barto_2018}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.19}\protected@file@percent }
\citation{noauthor_markov_2021}
\citation{noauthor_markov_2021}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite  {noauthor_markov_2021}\relax }}{5}{figure.caption.26}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_markov_2021}{{5}{2.2}{figure.caption.26}}}
\newlabel{fig:MDP}{{2.2}{5}{Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite {noauthor_markov_2021}\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.27}\protected@file@percent }
\citation{bellman_dynamic_1966}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.42}\protected@file@percent }
\@writefile{brf}{\backcite{bellman_dynamic_1966}{{6}{2.1}{section*.42}}}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.45}\protected@file@percent }
\citation{watkins_1989}
\citation{watkins_q-learning_1992}
\citation{mnih_human-level_2015}
\citation{dqn}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural networks}{7}{section.49}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Q-learning and Deep Q-learning}{7}{section.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.51}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_1989}{{7}{2.3}{section*.51}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.54}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_q-learning_1992}{{7}{2.3}{section*.54}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.55}\protected@file@percent }
\@writefile{brf}{\backcite{mnih_human-level_2015}{{7}{2.3}{section*.55}}}
\@writefile{brf}{\backcite{dqn}{{7}{2.3}{section*.55}}}
\citation{wiskunde_doubleq-learning_nodate}
\citation{van_hasselt_deep_2015}
\citation{wang_dueling_nodate}
\citation{goos_q-learning_1999}
\citation{dqn}
\citation{stateActionEmbeddings}
\citation{worldModels}
\citation{stateAggregation}
\citation{aggregationHierarchical}
\citation{barto_recent_2003}
\citation{dietterich_hierarchical_1999}
\citation{sutton_between_1999}
\citation{parr_reinforcement_nodate}
\citation{moerland_model-based_2020}
\citation{sutton_dyna_1991}
\citation{silver_mastering_2017}
\citation{worldModels}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.57}\protected@file@percent }
\@writefile{brf}{\backcite{wiskunde_doubleq-learning_nodate}{{8}{2.3}{section*.57}}}
\@writefile{brf}{\backcite{van_hasselt_deep_2015}{{8}{2.3}{section*.57}}}
\@writefile{brf}{\backcite{wang_dueling_nodate}{{8}{2.3}{section*.57}}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.59}\protected@file@percent }
\@writefile{brf}{\backcite{goos_q-learning_1999}{{8}{2.3}{section*.59}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem of large state-spaces}{8}{section.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.62}\protected@file@percent }
\@writefile{brf}{\backcite{dqn}{{8}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{stateActionEmbeddings}{{8}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{worldModels}{{8}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{stateAggregation}{{8}{2.4}{section*.62}}}
\@writefile{brf}{\backcite{aggregationHierarchical}{{8}{2.4}{section*.62}}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.63}\protected@file@percent }
\@writefile{brf}{\backcite{barto_recent_2003}{{8}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{dietterich_hierarchical_1999}{{8}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{sutton_between_1999}{{8}{2.4}{section*.63}}}
\@writefile{brf}{\backcite{parr_reinforcement_nodate}{{8}{2.4}{section*.63}}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.64}\protected@file@percent }
\@writefile{brf}{\backcite{moerland_model-based_2020}{{8}{2.4}{section*.64}}}
\@writefile{brf}{\backcite{sutton_dyna_1991}{{9}{2.4}{section*.64}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{9}{2.4}{section*.64}}}
\@writefile{brf}{\backcite{worldModels}{{9}{2.4}{section*.64}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}State-Decomposition method}{10}{chapter.66}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Originally proposed method}{10}{section.68}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }}{10}{figure.caption.71}\protected@file@percent }
\newlabel{fig:OneMDPtoManyMDPs}{{3.1}{10}{Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }{figure.caption.71}{}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.74}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }}{11}{figure.caption.75}\protected@file@percent }
\newlabel{fig:join_nets}{{3.2}{11}{The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Decomposing state trans. matrix, when this is known}{12}{section.80}\protected@file@percent }
\newlabel{sec:decomposing-trans-matrix}{{3.2}{12}{Decomposing state trans. matrix, when this is known}{section.80}{}}
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.81}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces State-decomposition algorithm.\relax }}{12}{algocf.83}\protected@file@percent }
\newlabel{algo:decompose}{{1}{12}{}{algocf.83}{}}
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.84}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces State-decomposition into given number of sub-spaces\relax }}{13}{algocf.86}\protected@file@percent }
\newlabel{algo:threshold}{{2}{13}{}{algocf.86}{}}
\citation{noauthor_cloud_nodate}
\citation{keras}
\citation{noauthor_tensorflow_nodate}
\citation{openai_gym_nodate}
\citation{noauthor_openai_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Design and testing}{14}{chapter.87}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Tools}{14}{section.89}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Python}{14}{section*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Google Colaboratory (Colab)}{14}{section*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Keras}{14}{section*.93}\protected@file@percent }
\@writefile{brf}{\backcite{keras}{{14}{4.1}{section*.93}}}
\@writefile{brf}{\backcite{noauthor_tensorflow_nodate}{{14}{4.1}{section*.93}}}
\@writefile{toc}{\contentsline {paragraph}{OpenAI Gym}{14}{section*.94}\protected@file@percent }
\@writefile{brf}{\backcite{openai_gym_nodate}{{14}{4.1}{section*.94}}}
\@writefile{brf}{\backcite{noauthor_cloud_nodate}{{14}{1}{section*.91}}}
\citation{noauthor_openai_nodate}
\citation{noauthor_openai_nodate}
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{15}{4.1}{section*.94}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite  {noauthor_openai_nodate}\relax }}{15}{figure.caption.95}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{15}{4.1}{figure.caption.95}}}
\newlabel{fig:cartpole}{{4.1}{15}{The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite {noauthor_openai_nodate}\relax }{figure.caption.95}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Environments}{15}{section.96}\protected@file@percent }
\newlabel{sec:TaxiTraps}{{4.2}{15}{Environments}{section.96}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.100}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.101}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.105}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Original and modified 'Taxi' environments.\relax }}{16}{figure.caption.106}\protected@file@percent }
\newlabel{fig:taxi}{{4.2}{16}{Original and modified 'Taxi' environments.\relax }{figure.caption.106}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {"Taxi"}}}{16}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {"TaxiTraps"}}}{16}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {"Taxi2"}}}{16}{subfigure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{17}{section*.111}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces State transition probabilities in the 'GridEps' environment.\relax }}{17}{table.caption.112}\protected@file@percent }
\newlabel{table:state-transitions-GridEps}{{4.1}{17}{State transition probabilities in the 'GridEps' environment.\relax }{table.caption.112}{}}
\@writefile{toc}{\contentsline {paragraph}{}{17}{section*.113}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 'Grid' environment. The dotted lines have no effect on the environment, they simply separate what will be referred to as the upper-left triangle and the lower-right triangle.\relax }}{18}{figure.caption.114}\protected@file@percent }
\newlabel{fig:grid}{{4.3}{18}{'Grid' environment. The dotted lines have no effect on the environment, they simply separate what will be referred to as the upper-left triangle and the lower-right triangle.\relax }{figure.caption.114}{}}
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.115}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.116}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Benchmark DQN agent}{18}{section.117}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.118}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.119}\protected@file@percent }
\citation{kingma_adam_2017}
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.120}\protected@file@percent }
\@writefile{brf}{\backcite{kingma_adam_2017}{{19}{4.3}{section*.120}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }}{19}{figure.caption.123}\protected@file@percent }
\newlabel{fig:DQN-network}{{4.4}{19}{The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }{figure.caption.123}{}}
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.124}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Ensuring fair comparison}{19}{section.125}\protected@file@percent }
\newlabel{sec:fair-comparison}{{4.4}{19}{Ensuring fair comparison}{section.125}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{20}{chapter.126}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{20}{Results}{chapter.126}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation method}{20}{section.127}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.128}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces An example of an 'average reward' vs 'samples' graph. The black line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }}{20}{figure.caption.129}\protected@file@percent }
\newlabel{fig:samples-graph}{{5.1}{20}{An example of an 'average reward' vs 'samples' graph. The black line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }{figure.caption.129}{}}
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.130}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Effect of state representations}{21}{section.131}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }}{22}{figure.caption.136}\protected@file@percent }
\newlabel{fig:effect-state-encoding}{{5.2}{22}{Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }{figure.caption.136}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Effect of the NN's size}{22}{section.137}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }}{23}{figure.caption.138}\protected@file@percent }
\newlabel{fig:effect_NN_dimension}{{5.3}{23}{Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }{figure.caption.138}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Initial results}{23}{section.139}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }}{23}{figure.caption.140}\protected@file@percent }
\newlabel{fig:two_stage}{{5.4}{23}{Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }{figure.caption.140}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}A simple approach to decomposition: 'DeltaSwitch'}{23}{section.141}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Combining 'NN0' and 'NN1' using another NN.\relax }}{24}{figure.caption.143}\protected@file@percent }
\newlabel{fig:combined-network}{{5.5}{24}{Combining 'NN0' and 'NN1' using another NN.\relax }{figure.caption.143}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Taxi2 environment.\relax }}{25}{figure.caption.144}\protected@file@percent }
\newlabel{fig:Taxi2-dqn-deltaSwitch}{{5.6}{25}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Taxi2 environment.\relax }{figure.caption.144}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }}{25}{figure.caption.145}\protected@file@percent }
\newlabel{fig:gridNoWall-dqn-deltaSwitch}{{5.7}{25}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }{figure.caption.145}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparison of DeltaSwitch with different $\delta $.\relax }}{26}{figure.caption.146}\protected@file@percent }
\newlabel{fig:gridNoWall-deltaSwitch-compareDelta}{{5.8}{26}{Comparison of DeltaSwitch with different $\delta $.\relax }{figure.caption.146}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Effect of using reduced encoding}{26}{section.147}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Effect of reducing the input size.\relax }}{27}{figure.caption.148}\protected@file@percent }
\newlabel{fig:reduced-effect}{{5.9}{27}{Effect of reducing the input size.\relax }{figure.caption.148}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Samples plots}{27}{section.149}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Effect of wall / no wall}{27}{section.150}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }}{28}{figure.caption.151}\protected@file@percent }
\newlabel{fig:wall}{{5.10}{28}{Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }{figure.caption.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.9}Effect of decomposing by destination or by position}{28}{section.152}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Effect of different state encoding methods on the performance of 'DeltaSwitch' in the 'Grid' environment.\relax }}{29}{figure.caption.153}\protected@file@percent }
\newlabel{fig:effect-state-encoding}{{5.11}{29}{Effect of different state encoding methods on the performance of 'DeltaSwitch' in the 'Grid' environment.\relax }{figure.caption.153}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }}{29}{figure.caption.154}\protected@file@percent }
\newlabel{fig:one-hot}{{5.12}{29}{Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }{figure.caption.154}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.10}A different approach based on transfer learning}{29}{section.155}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \tmspace  +\thickmuskip {.2777em}1\%$.\relax }}{30}{figure.caption.156}\protected@file@percent }
\newlabel{fig:learnSwitch1}{{5.13}{30}{Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \;1\%$.\relax }{figure.caption.156}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }}{31}{figure.caption.158}\protected@file@percent }
\newlabel{fig:initialisedLearnSwitch}{{5.14}{31}{Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }{figure.caption.158}{}}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }}{32}{figure.caption.161}\protected@file@percent }
\newlabel{fig:SARSA-progressive}{{5.15}{32}{Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }{figure.caption.161}{}}
\@writefile{brf}{\backcite{rusu_progressive_2016}{{32}{5.10}{figure.caption.161}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Structure of progressive network when training the third task. Figure taken from \cite  {rusu_progressive_2016}.\relax }}{32}{figure.caption.162}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{32}{5.16}{figure.caption.162}}}
\newlabel{fig:progressive-3-tasks}{{5.16}{32}{Structure of progressive network when training the third task. Figure taken from \cite {rusu_progressive_2016}.\relax }{figure.caption.162}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.11}Techniques to learn the 'switch'}{33}{section.163}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }}{33}{figure.caption.166}\protected@file@percent }
\newlabel{fig:progressive-combining-simultaneous}{{5.17}{33}{Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }{figure.caption.166}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the comining network itself. $h$ indicates hidden layers of the network.\relax }}{34}{figure.caption.167}\protected@file@percent }
\newlabel{fig:modified-progressive}{{5.18}{34}{Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the comining network itself. $h$ indicates hidden layers of the network.\relax }{figure.caption.167}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.12}Can have separate subsection for things that didn't work}{35}{section.168}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Applicability of the proposed technique}{36}{chapter.169}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.170}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.171}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Allocation of resources problem for two interconnected data centres.\relax }}{36}{figure.caption.172}\protected@file@percent }
\newlabel{fig:data-centres}{{6.1}{36}{Allocation of resources problem for two interconnected data centres.\relax }{figure.caption.172}{}}
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.173}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.174}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.175}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Possible state-decomposition agent.\relax }}{38}{figure.caption.176}\protected@file@percent }
\newlabel{fig:data-centres-decomposition-agent}{{6.2}{38}{Possible state-decomposition agent.\relax }{figure.caption.176}{}}
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.177}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.178}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions and Further Work}{39}{chapter.179}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Findings}{39}{section.180}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Discussion}{39}{section.181}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.184}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Finding the state-transition matrix}{39}{section*.185}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Extensions}{40}{section.186}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Compression and embeddings of states}{40}{section*.187}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to continuous state-spaces}{40}{section*.188}\protected@file@percent }
\newlabel{sec:different-decompositions}{{7.3}{40}{Applying state-decomposition to continuous state-spaces}{section*.188}{}}
\@writefile{toc}{\contentsline {paragraph}{Different types of decomposition}{40}{section*.189}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Offline training}{40}{section*.190}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sharing information between sub-agents}{40}{section*.191}\protected@file@percent }
\citation{simsek_identifying_2005}
\citation{menache_q-cutdynamic_2002}
\bibstyle{plain}
\bibdata{bibliography/bibliography,bibliography/zotero}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }}{41}{figure.caption.192}\protected@file@percent }
\newlabel{fig:connected-states}{{7.1}{41}{MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }{figure.caption.192}{}}
\@writefile{toc}{\contentsline {paragraph}{Using state-decomposition for automatic sub-goal discovery}{41}{section*.193}\protected@file@percent }
\@writefile{brf}{\backcite{simsek_identifying_2005}{{41}{7.3}{section*.193}}}
\@writefile{brf}{\backcite{menache_q-cutdynamic_2002}{{41}{7.3}{section*.193}}}
\@writefile{toc}{\contentsline {paragraph}{Proving mathematical bounds}{41}{section*.194}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to policy gradient algorithms}{41}{section*.195}\protected@file@percent }
\bibcite{noauthor_cloud_nodate}{1}
\bibcite{noauthor_google_nodate}{2}
\bibcite{noauthor_markov_2021}{3}
\bibcite{noauthor_openai_nodate}{4}
\bibcite{noauthor_tensorflow_nodate}{5}
\bibcite{aggregationHierarchical}{6}
\bibcite{autonomousDriving}{7}
\bibcite{barto_recent_2003}{8}
\bibcite{bellman_dynamic_1966}{9}
\bibcite{stateAggregation}{10}
\bibcite{dietterich_hierarchical_1999}{11}
\bibcite{goos_q-learning_1999}{12}
\bibcite{worldModels}{13}
\bibcite{kingma_adam_2017}{14}
\bibcite{menache_q-cutdynamic_2002}{15}
\bibcite{dqn}{16}
\bibcite{mnih_human-level_2015}{17}
\bibcite{moerland_model-based_2020}{18}
\bibcite{openai_gym_nodate}{19}
\bibcite{parr_reinforcement_nodate}{20}
\bibcite{NLP}{21}
\bibcite{stateActionEmbeddings}{22}
\bibcite{rusu_progressive_2016}{23}
\bibcite{silver_mastering_2017}{24}
\bibcite{sutton_dyna_1991}{25}
\bibcite{sutton_barto_2018}{26}
\bibcite{sutton_between_1999}{27}
\bibcite{keras}{28}
\bibcite{van_hasselt_deep_2015}{29}
\bibcite{wang_dueling_nodate}{30}
\bibcite{watkins_q-learning_1992}{31}
\bibcite{watkins_1989}{32}
\bibcite{wiskunde_doubleq-learning_nodate}{33}
\bibcite{yu_reinforcement_2020}{34}
\bibcite{ServicePlacement}{35}
\bibcite{SDNSynchronisation}{36}
\bibcite{simsek_identifying_2005}{37}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Code}{45}{appendix.197}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{45}{Code}{appendix.197}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.1}Function which is given the state-transition matrix in input and combines the thresholding of its values with the decomposition into separate MDPs, returning \texttt  {d} which is a list indicating which sub-space each state belongs to (as an index) and \texttt  {groups} which is a list of lists containing the states of each sub-space.}{45}{lstlisting.199}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.2}Function that given the state-transition and a target number of subspaces performs the state-decomposition with different thresholds in order to obtain the correct number of sub-spaces.}{45}{lstlisting.221}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {A.3}Current version of my state-decomposition agent. In this version the states are fed in the neural networks as one-hot-encoded integers.}{46}{lstlisting.246}\protected@file@percent }
