\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\citation{sutton_barto_2018}
\citation{silver_mastering_2017}
\citation{yu_reinforcement_2020}
\citation{noauthor_google_nodate}
\citation{autonomousDriving}
\citation{NLP}
\citation{ServicePlacement}
\citation{SDNSynchronisation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.5}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{yu_reinforcement_2020}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{noauthor_google_nodate}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{autonomousDriving}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{NLP}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{ServicePlacement}{{2}{1.1}{section*.5}}}
\@writefile{brf}{\backcite{SDNSynchronisation}{{2}{1.1}{section*.5}}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Definition}{2}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure of the report}{3}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.11}\protected@file@percent }
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{4}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{4}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.14}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{section*.14}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction of the agent with the environment during time step $t$. Figure taken from \cite  {sutton_barto_2018}\relax }}{4}{figure.caption.15}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{figure.caption.15}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agent-env-interaction}{{2.1}{4}{Interaction of the agent with the environment during time step $t$. Figure taken from \cite {sutton_barto_2018}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.19}\protected@file@percent }
\citation{noauthor_markov_2021}
\citation{noauthor_markov_2021}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite  {noauthor_markov_2021}\relax }}{6}{figure.caption.26}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_markov_2021}{{6}{2.2}{figure.caption.26}}}
\newlabel{fig:MDP}{{2.2}{6}{Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite {noauthor_markov_2021}\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.27}\protected@file@percent }
\citation{bellman_dynamic_1966}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.42}\protected@file@percent }
\@writefile{brf}{\backcite{bellman_dynamic_1966}{{7}{2.1}{section*.42}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.45}\protected@file@percent }
\citation{sharma_what_2019}
\citation{sharma_what_2019}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Artificial Neural Networks}{8}{section.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.51}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Graphical representation of a perceptron. Figure taken from \cite  {sharma_what_2019}.\relax }}{8}{figure.caption.52}\protected@file@percent }
\@writefile{brf}{\backcite{sharma_what_2019}{{8}{2.3}{figure.caption.52}}}
\newlabel{fig:perceptron}{{2.3}{8}{Graphical representation of a perceptron. Figure taken from \cite {sharma_what_2019}.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.53}\protected@file@percent }
\citation{watkins_1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Fully-connected neural network.\relax }}{9}{figure.caption.54}\protected@file@percent }
\newlabel{fig:fully-connected}{{2.4}{9}{Fully-connected neural network.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.55}\protected@file@percent }
\citation{watkins_q-learning_1992}
\citation{mnih_human-level_2015}
\citation{dqn}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Q-learning and Deep Q-learning}{10}{section.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.57}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_1989}{{10}{2.3}{section*.57}}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.60}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_q-learning_1992}{{10}{2.3}{section*.60}}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.61}\protected@file@percent }
\@writefile{brf}{\backcite{mnih_human-level_2015}{{10}{2.3}{section*.61}}}
\@writefile{brf}{\backcite{dqn}{{10}{2.3}{section*.61}}}
\citation{wiskunde_doubleq-learning_nodate}
\citation{van_hasselt_deep_2015}
\citation{wang_dueling_nodate}
\citation{goos_q-learning_1999}
\citation{dqn}
\citation{stateActionEmbeddings}
\citation{worldModels}
\citation{stateAggregation}
\citation{aggregationHierarchical}
\citation{barto_recent_2003}
\citation{dietterich_hierarchical_1999}
\citation{sutton_between_1999}
\citation{parr_reinforcement_nodate}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.63}\protected@file@percent }
\@writefile{brf}{\backcite{wiskunde_doubleq-learning_nodate}{{11}{2.3}{section*.63}}}
\@writefile{brf}{\backcite{van_hasselt_deep_2015}{{11}{2.3}{section*.63}}}
\@writefile{brf}{\backcite{wang_dueling_nodate}{{11}{2.3}{section*.63}}}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.65}\protected@file@percent }
\@writefile{brf}{\backcite{goos_q-learning_1999}{{11}{2.3}{section*.65}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem of large state-spaces}{11}{section.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.68}\protected@file@percent }
\@writefile{brf}{\backcite{dqn}{{11}{2.4}{section*.68}}}
\@writefile{brf}{\backcite{stateActionEmbeddings}{{11}{2.4}{section*.68}}}
\@writefile{brf}{\backcite{worldModels}{{11}{2.4}{section*.68}}}
\@writefile{brf}{\backcite{stateAggregation}{{11}{2.4}{section*.68}}}
\@writefile{brf}{\backcite{aggregationHierarchical}{{11}{2.4}{section*.68}}}
\citation{moerland_model-based_2020}
\citation{sutton_dyna_1991}
\citation{silver_mastering_2017}
\citation{worldModels}
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.69}\protected@file@percent }
\@writefile{brf}{\backcite{barto_recent_2003}{{12}{2.4}{section*.69}}}
\@writefile{brf}{\backcite{dietterich_hierarchical_1999}{{12}{2.4}{section*.69}}}
\@writefile{brf}{\backcite{sutton_between_1999}{{12}{2.4}{section*.69}}}
\@writefile{brf}{\backcite{parr_reinforcement_nodate}{{12}{2.4}{section*.69}}}
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.70}\protected@file@percent }
\@writefile{brf}{\backcite{moerland_model-based_2020}{{12}{2.4}{section*.70}}}
\@writefile{brf}{\backcite{sutton_dyna_1991}{{12}{2.4}{section*.70}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{12}{2.4}{section*.70}}}
\@writefile{brf}{\backcite{worldModels}{{12}{2.4}{section*.70}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}State-Decomposition method}{13}{chapter.72}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Originally proposed method}{13}{section.74}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.76}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }}{14}{figure.caption.78}\protected@file@percent }
\newlabel{fig:OneMDPtoManyMDPs}{{3.1}{14}{Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }{figure.caption.78}{}}
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.81}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }}{15}{figure.caption.82}\protected@file@percent }
\newlabel{fig:join_nets}{{3.2}{15}{The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN.\relax }{figure.caption.82}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.83}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Decomposing state trans. matrix, when this is known}{16}{section.86}\protected@file@percent }
\newlabel{sec:decomposing-trans-matrix}{{3.2}{16}{Decomposing state trans. matrix, when this is known}{section.86}{}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.87}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces State-decomposition algorithm.\relax }}{17}{algocf.89}\protected@file@percent }
\newlabel{algo:decompose}{{1}{17}{}{algocf.89}{}}
\@writefile{toc}{\contentsline {paragraph}{}{17}{section*.90}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces State-decomposition into given number of sub-spaces\relax }}{17}{algocf.92}\protected@file@percent }
\newlabel{algo:threshold}{{2}{17}{}{algocf.92}{}}
\citation{noauthor_cloud_nodate}
\citation{keras}
\citation{noauthor_tensorflow_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experimental method}{18}{chapter.93}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.94}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Tools}{18}{section.95}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Python}{18}{section*.96}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Google Colaboratory (Colab)}{18}{section*.97}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_cloud_nodate}{{18}{1}{section*.97}}}
\citation{openai_gym_nodate}
\citation{noauthor_openai_nodate}
\citation{noauthor_openai_nodate}
\citation{noauthor_openai_nodate}
\@writefile{toc}{\contentsline {paragraph}{Keras}{19}{section*.99}\protected@file@percent }
\@writefile{brf}{\backcite{keras}{{19}{4.1}{section*.99}}}
\@writefile{brf}{\backcite{noauthor_tensorflow_nodate}{{19}{4.1}{section*.99}}}
\@writefile{toc}{\contentsline {paragraph}{OpenAI Gym}{19}{section*.100}\protected@file@percent }
\@writefile{brf}{\backcite{openai_gym_nodate}{{19}{4.1}{section*.100}}}
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{19}{4.1}{section*.100}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite  {noauthor_openai_nodate}\relax }}{19}{figure.caption.101}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{19}{4.1}{figure.caption.101}}}
\newlabel{fig:cartpole}{{4.1}{19}{The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite {noauthor_openai_nodate}\relax }{figure.caption.101}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Environments}{19}{section.102}\protected@file@percent }
\newlabel{sec:TaxiTraps}{{4.2}{19}{Environments}{section.102}{}}
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{21}{section*.111}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Original and modified 'Taxi' environments.\relax }}{21}{figure.caption.112}\protected@file@percent }
\newlabel{fig:taxi}{{4.2}{21}{Original and modified 'Taxi' environments.\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {"Taxi"}}}{21}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {"TaxiTraps"}}}{21}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {"Taxi2"}}}{21}{subfigure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{21}{section*.116}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.117}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces State transition probabilities in the 'GridEps' environment.\relax }}{22}{table.caption.118}\protected@file@percent }
\newlabel{table:state-transitions-GridEps}{{4.1}{22}{State transition probabilities in the 'GridEps' environment.\relax }{table.caption.118}{}}
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.120}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 'Grid' environment. The dotted lines have no effect on the environment, they simply separate what will be referred to as the upper-left triangle and the lower-right triangle.\relax }}{23}{figure.caption.121}\protected@file@percent }
\newlabel{fig:grid}{{4.3}{23}{'Grid' environment. The dotted lines have no effect on the environment, they simply separate what will be referred to as the upper-left triangle and the lower-right triangle.\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {paragraph}{}{23}{section*.122}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{23}{section*.123}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Benchmark DQN agent}{23}{section.124}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{23}{section*.125}\protected@file@percent }
\citation{kingma_adam_2017}
\@writefile{toc}{\contentsline {paragraph}{}{24}{section*.126}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{24}{section*.127}\protected@file@percent }
\@writefile{brf}{\backcite{kingma_adam_2017}{{24}{4.3}{section*.127}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }}{25}{figure.caption.131}\protected@file@percent }
\newlabel{fig:DQN-network}{{4.4}{25}{The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }{figure.caption.131}{}}
\@writefile{toc}{\contentsline {paragraph}{}{25}{section*.132}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Ensuring fair comparison}{25}{section.133}\protected@file@percent }
\newlabel{sec:fair-comparison}{{4.4}{25}{Ensuring fair comparison}{section.133}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{26}{chapter.134}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{26}{Results}{chapter.134}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation method}{26}{section.135}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{26}{section*.136}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces An example of an 'average reward' vs 'samples' graph. The black line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }}{27}{figure.caption.137}\protected@file@percent }
\newlabel{fig:samples-graph}{{5.1}{27}{An example of an 'average reward' vs 'samples' graph. The black line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }{figure.caption.137}{}}
\@writefile{toc}{\contentsline {paragraph}{}{27}{section*.138}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Effect of state representations}{27}{section.139}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{27}{section*.140}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }}{28}{figure.caption.145}\protected@file@percent }
\newlabel{fig:effect-state-encoding}{{5.2}{28}{Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }{figure.caption.145}{}}
\@writefile{toc}{\contentsline {paragraph}{}{29}{section*.146}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Effect of the NN's size}{29}{section.147}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }}{30}{figure.caption.148}\protected@file@percent }
\newlabel{fig:effect_NN_dimension}{{5.3}{30}{Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }{figure.caption.148}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Initial results}{30}{section.149}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }}{31}{figure.caption.150}\protected@file@percent }
\newlabel{fig:two_stage}{{5.4}{31}{Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }{figure.caption.150}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}A simple approach to decomposition: 'DeltaSwitch'}{31}{section.151}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{31}{section*.152}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces 'DeltaSwitch' architecture with $\delta =0$. In this case, the weighted sum effectively acts as a switch, which selects the output of the network corresponding to the sub-space of the input state.\relax }}{32}{figure.caption.154}\protected@file@percent }
\newlabel{fig:delta-switch}{{5.5}{32}{'DeltaSwitch' architecture with $\delta =0$. In this case, the weighted sum effectively acts as a switch, which selects the output of the network corresponding to the sub-space of the input state.\relax }{figure.caption.154}{}}
\@writefile{toc}{\contentsline {paragraph}{}{32}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{33}{section*.156}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }}{33}{figure.caption.157}\protected@file@percent }
\newlabel{fig:gridNoWall-dqn-deltaSwitch}{{5.6}{33}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }{figure.caption.157}{}}
\@writefile{toc}{\contentsline {paragraph}{}{33}{section*.158}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.159}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.160}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparison of DeltaSwitch with different $\delta $.\relax }}{34}{figure.caption.162}\protected@file@percent }
\newlabel{fig:gridNoWall-deltaSwitch-compareDelta}{{5.7}{34}{Comparison of DeltaSwitch with different $\delta $.\relax }{figure.caption.162}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Applying 'DeltaSwitch' to non-prefectly decomposable environment}{35}{subsection.163}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.164}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.166}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.167}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.168}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }}{36}{figure.caption.165}\protected@file@percent }
\newlabel{fig:deltaSwitch-GridEps}{{5.8}{36}{DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }{figure.caption.165}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Effect of using reduced encoding}{37}{subsection.169}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.170}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Effect of reducing the input size.\relax }}{37}{figure.caption.171}\protected@file@percent }
\newlabel{fig:reduced-effect}{{5.9}{37}{Effect of reducing the input size.\relax }{figure.caption.171}{}}
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.172}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Effect of wall}{38}{subsection.174}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.175}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.176}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }}{38}{figure.caption.177}\protected@file@percent }
\newlabel{fig:wall}{{5.10}{38}{Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }{figure.caption.177}{}}
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.178}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.6}A different approach based on transfer learning}{39}{section.179}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.180}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Combining 'NN0' and 'NN1' using another NN.\relax }}{39}{figure.caption.181}\protected@file@percent }
\newlabel{fig:combined-network}{{5.11}{39}{Combining 'NN0' and 'NN1' using another NN.\relax }{figure.caption.181}{}}
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{40}{section*.184}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \tmspace  +\thickmuskip {.2777em}1\%$.\relax }}{40}{figure.caption.185}\protected@file@percent }
\newlabel{fig:learnSwitch1}{{5.12}{40}{Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \;1\%$.\relax }{figure.caption.185}{}}
\@writefile{toc}{\contentsline {paragraph}{}{40}{section*.186}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }}{41}{figure.caption.189}\protected@file@percent }
\newlabel{fig:initialisedLearnSwitch}{{5.13}{41}{Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }{figure.caption.189}{}}
\@writefile{toc}{\contentsline {paragraph}{}{41}{section*.190}\protected@file@percent }
\citation{rusu_progressive_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }}{42}{figure.caption.193}\protected@file@percent }
\newlabel{fig:SARSA-progressive}{{5.14}{42}{Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }{figure.caption.193}{}}
\@writefile{toc}{\contentsline {paragraph}{}{42}{section*.194}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{42}{5.6}{section*.194}}}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Structure of progressive network when training the third task. Figure taken from \cite  {rusu_progressive_2016}.\relax }}{43}{figure.caption.196}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{43}{5.15}{figure.caption.196}}}
\newlabel{fig:progressive-3-tasks}{{5.15}{43}{Structure of progressive network when training the third task. Figure taken from \cite {rusu_progressive_2016}.\relax }{figure.caption.196}{}}
\@writefile{toc}{\contentsline {paragraph}{}{43}{section*.197}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the combining network itself. $h$ indicates hidden layers of the network.\relax }}{44}{figure.caption.198}\protected@file@percent }
\newlabel{fig:modified-progressive}{{5.16}{44}{Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the combining network itself. $h$ indicates hidden layers of the network.\relax }{figure.caption.198}{}}
\@writefile{toc}{\contentsline {paragraph}{}{44}{section*.199}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Techniques to learn the 'switch'}{44}{section.200}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{44}{section*.201}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{45}{section*.203}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }}{45}{figure.caption.206}\protected@file@percent }
\newlabel{fig:progressive-combining-simultaneous}{{5.17}{45}{Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }{figure.caption.206}{}}
\@writefile{toc}{\contentsline {paragraph}{}{46}{section*.207}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{46}{section*.208}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Applicability of the proposed techniques}{47}{chapter.209}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{47}{section*.210}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{47}{section*.211}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Allocation of resources problem for two interconnected data centres.\relax }}{47}{figure.caption.212}\protected@file@percent }
\newlabel{fig:data-centres}{{6.1}{47}{Allocation of resources problem for two interconnected data centres.\relax }{figure.caption.212}{}}
\@writefile{toc}{\contentsline {paragraph}{}{48}{section*.213}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{48}{section*.214}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{48}{section*.215}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Possible state-decomposition agent.\relax }}{49}{figure.caption.216}\protected@file@percent }
\newlabel{fig:data-centres-decomposition-agent}{{6.2}{49}{Possible state-decomposition agent.\relax }{figure.caption.216}{}}
\@writefile{toc}{\contentsline {paragraph}{}{49}{section*.217}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{49}{section*.218}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions and Further Work}{51}{chapter.219}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Findings}{51}{section.220}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{51}{section*.221}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{51}{section*.222}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{51}{section*.223}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.224}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.225}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Discussion}{52}{section.226}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.227}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.228}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.229}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.230}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.231}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Extensions}{53}{section.232}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Finding the state-transition matrix}{53}{section*.233}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Compression and embeddings of states}{54}{section*.234}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to continuous state-spaces}{54}{section*.235}\protected@file@percent }
\newlabel{sec:different-decompositions}{{7.3}{54}{Applying state-decomposition to continuous state-spaces}{section*.235}{}}
\@writefile{toc}{\contentsline {paragraph}{Different types of decomposition}{54}{section*.236}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sharing information between sub-agents}{54}{section*.237}\protected@file@percent }
\citation{simsek_identifying_2005}
\citation{menache_q-cutdynamic_2002}
\bibstyle{plain}
\bibdata{bibliography/bibliography,bibliography/zotero}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }}{55}{figure.caption.238}\protected@file@percent }
\newlabel{fig:connected-states}{{7.1}{55}{MDP composed of smaller sub-spaces of states connected by few but probable transitions.\relax }{figure.caption.238}{}}
\@writefile{toc}{\contentsline {paragraph}{Using state-decomposition for automatic sub-goal discovery}{55}{section*.239}\protected@file@percent }
\@writefile{brf}{\backcite{simsek_identifying_2005}{{55}{7.3}{section*.239}}}
\@writefile{brf}{\backcite{menache_q-cutdynamic_2002}{{55}{7.3}{section*.239}}}
\@writefile{toc}{\contentsline {paragraph}{Proving mathematical bounds}{55}{section*.240}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to policy gradient algorithms}{55}{section*.241}\protected@file@percent }
\bibcite{noauthor_cloud_nodate}{1}
\bibcite{noauthor_google_nodate}{2}
\bibcite{noauthor_markov_2021}{3}
\bibcite{noauthor_openai_nodate}{4}
\bibcite{noauthor_tensorflow_nodate}{5}
\bibcite{aggregationHierarchical}{6}
\bibcite{autonomousDriving}{7}
\bibcite{barto_recent_2003}{8}
\bibcite{bellman_dynamic_1966}{9}
\bibcite{stateAggregation}{10}
\bibcite{dietterich_hierarchical_1999}{11}
\bibcite{goos_q-learning_1999}{12}
\bibcite{worldModels}{13}
\bibcite{kingma_adam_2017}{14}
\bibcite{menache_q-cutdynamic_2002}{15}
\bibcite{dqn}{16}
\bibcite{mnih_human-level_2015}{17}
\bibcite{moerland_model-based_2020}{18}
\bibcite{openai_gym_nodate}{19}
\bibcite{parr_reinforcement_nodate}{20}
\bibcite{NLP}{21}
\bibcite{stateActionEmbeddings}{22}
\bibcite{rusu_progressive_2016}{23}
\bibcite{sharma_what_2019}{24}
\bibcite{silver_mastering_2017}{25}
\bibcite{sutton_dyna_1991}{26}
\bibcite{sutton_barto_2018}{27}
\bibcite{sutton_between_1999}{28}
\bibcite{keras}{29}
\bibcite{van_hasselt_deep_2015}{30}
\bibcite{wang_dueling_nodate}{31}
\bibcite{watkins_q-learning_1992}{32}
\bibcite{watkins_1989}{33}
\bibcite{wiskunde_doubleq-learning_nodate}{34}
\bibcite{yu_reinforcement_2020}{35}
\bibcite{ServicePlacement}{36}
\bibcite{SDNSynchronisation}{37}
\bibcite{simsek_identifying_2005}{38}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Performance graphs}{59}{appendix.243}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{appendix-graphs}{{A}{59}{Performance graphs}{appendix.243}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the 'Taxi2' environment.\relax }}{59}{figure.caption.244}\protected@file@percent }
\newlabel{fig:Taxi2-dqn-deltaSwitch}{{A.1}{59}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the 'Taxi2' environment.\relax }{figure.caption.244}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }}{59}{figure.caption.245}\protected@file@percent }
\newlabel{fig:one-hot}{{A.2}{59}{Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }{figure.caption.245}{}}
