\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {paragraph}{}{i}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{i}{section*.3}\protected@file@percent }
\citation{sutton_barto_2018}
\citation{silver_mastering_2017}
\citation{yu_reinforcement_2020}
\citation{noauthor_google_nodate}
\citation{autonomousDriving}
\citation{NLP}
\citation{ServicePlacement}
\citation{SDNSynchronisation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{2}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.8}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{yu_reinforcement_2020}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{noauthor_google_nodate}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{autonomousDriving}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{NLP}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{ServicePlacement}{{2}{1.1}{section*.8}}}
\@writefile{brf}{\backcite{SDNSynchronisation}{{2}{1.1}{section*.8}}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Definition}{2}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure of the report}{3}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.14}\protected@file@percent }
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\citation{sutton_barto_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{4}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{4}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.17}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{section*.17}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction of the agent with the environment during time step $t$. Figure taken from \cite  {sutton_barto_2018}.\relax }}{4}{figure.caption.18}\protected@file@percent }
\@writefile{brf}{\backcite{sutton_barto_2018}{{4}{2.1}{figure.caption.18}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agent-env-interaction}{{2.1}{4}{Interaction of the agent with the environment during time step $t$. Figure taken from \cite {sutton_barto_2018}.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.22}\protected@file@percent }
\citation{noauthor_markov_2021}
\citation{noauthor_markov_2021}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.25}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite  {noauthor_markov_2021}\relax }}{6}{figure.caption.29}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_markov_2021}{{6}{2.2}{figure.caption.29}}}
\newlabel{fig:MDP}{{2.2}{6}{Graph representation of a Markov Decision Process. Note the rewards (zigzag arrows) that are released in certain transitions. \cite {noauthor_markov_2021}\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{}{6}{section*.30}\protected@file@percent }
\citation{bellman_dynamic_1966}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.45}\protected@file@percent }
\@writefile{brf}{\backcite{bellman_dynamic_1966}{{7}{2.1}{section*.45}}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.51}\protected@file@percent }
\citation{sharma_what_2019}
\citation{sharma_what_2019}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Artificial Neural Networks}{8}{section.52}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.54}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Graphical representation of a perceptron. Figure taken from \cite  {sharma_what_2019}.\relax }}{8}{figure.caption.55}\protected@file@percent }
\@writefile{brf}{\backcite{sharma_what_2019}{{8}{2.3}{figure.caption.55}}}
\newlabel{fig:perceptron}{{2.3}{8}{Graphical representation of a perceptron. Figure taken from \cite {sharma_what_2019}.\relax }{figure.caption.55}{}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.56}\protected@file@percent }
\citation{watkins_1989}
\citation{watkins_q-learning_1992}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Fully-connected neural network.\relax }}{9}{figure.caption.57}\protected@file@percent }
\newlabel{fig:fully-connected}{{2.4}{9}{Fully-connected neural network.\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Q-learning and Deep Q-learning}{9}{section.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.60}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_1989}{{9}{2.3}{section*.60}}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.62}\protected@file@percent }
\citation{mnih_human-level_2015}
\citation{dqn}
\citation{wiskunde_doubleq-learning_nodate}
\citation{van_hasselt_deep_2015}
\citation{wang_dueling_nodate}
\citation{goos_q-learning_1999}
\citation{dqn}
\citation{stateActionEmbeddings}
\citation{worldModels}
\citation{stateAggregation}
\citation{aggregationHierarchical}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.63}\protected@file@percent }
\@writefile{brf}{\backcite{watkins_q-learning_1992}{{10}{2.3}{section*.63}}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.64}\protected@file@percent }
\@writefile{brf}{\backcite{mnih_human-level_2015}{{10}{2.3}{section*.64}}}
\@writefile{brf}{\backcite{dqn}{{10}{2.3}{section*.64}}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.66}\protected@file@percent }
\@writefile{brf}{\backcite{wiskunde_doubleq-learning_nodate}{{10}{2.3}{section*.66}}}
\@writefile{brf}{\backcite{van_hasselt_deep_2015}{{10}{2.3}{section*.66}}}
\@writefile{brf}{\backcite{wang_dueling_nodate}{{10}{2.3}{section*.66}}}
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.68}\protected@file@percent }
\@writefile{brf}{\backcite{goos_q-learning_1999}{{10}{2.3}{section*.68}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problem of large state spaces}{10}{section.69}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{10}{section*.70}\protected@file@percent }
\citation{barto_recent_2003}
\citation{dietterich_hierarchical_1999}
\citation{sutton_between_1999}
\citation{parr_reinforcement_nodate}
\citation{moerland_model-based_2020}
\citation{sutton_dyna_1991}
\citation{silver_mastering_2017}
\citation{worldModels}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.71}\protected@file@percent }
\@writefile{brf}{\backcite{dqn}{{11}{2.4}{section*.71}}}
\@writefile{brf}{\backcite{stateActionEmbeddings}{{11}{2.4}{section*.71}}}
\@writefile{brf}{\backcite{worldModels}{{11}{2.4}{section*.71}}}
\@writefile{brf}{\backcite{stateAggregation}{{11}{2.4}{section*.71}}}
\@writefile{brf}{\backcite{aggregationHierarchical}{{11}{2.4}{section*.71}}}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.72}\protected@file@percent }
\@writefile{brf}{\backcite{barto_recent_2003}{{11}{2.4}{section*.72}}}
\@writefile{brf}{\backcite{dietterich_hierarchical_1999}{{11}{2.4}{section*.72}}}
\@writefile{brf}{\backcite{sutton_between_1999}{{11}{2.4}{section*.72}}}
\@writefile{brf}{\backcite{parr_reinforcement_nodate}{{11}{2.4}{section*.72}}}
\@writefile{toc}{\contentsline {paragraph}{}{11}{section*.73}\protected@file@percent }
\@writefile{brf}{\backcite{moerland_model-based_2020}{{11}{2.4}{section*.73}}}
\@writefile{brf}{\backcite{sutton_dyna_1991}{{11}{2.4}{section*.73}}}
\@writefile{brf}{\backcite{silver_mastering_2017}{{11}{2.4}{section*.73}}}
\@writefile{brf}{\backcite{worldModels}{{11}{2.4}{section*.73}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}state-decomposition method}{12}{chapter.75}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Originally proposed method}{12}{section.77}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{12}{section*.79}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }}{13}{figure.caption.81}\protected@file@percent }
\newlabel{fig:OneMDPtoManyMDPs}{{3.1}{13}{Applying a threshold to the state transition matrix and normalising the probabilities can cause the MDP to separate into separate MDPs as it reduces the number of possible transitions.\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{13}{section*.84}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN architecture.\relax }}{14}{figure.caption.85}\protected@file@percent }
\newlabel{fig:join_nets}{{3.2}{14}{The NNs of the decomposed states' agents are merged as input of another NN to form a new bigger NN architecture.\relax }{figure.caption.85}{}}
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{14}{section*.87}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Decomposing the state-trans. matrix}{15}{section.89}\protected@file@percent }
\newlabel{sec:decomposing-trans-matrix}{{3.2}{15}{Decomposing the state-trans. matrix}{section.89}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.90}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces State-decomposition algorithm.\relax }}{15}{algocf.92}\protected@file@percent }
\newlabel{algo:decompose}{{1}{15}{}{algocf.92}{}}
\@writefile{toc}{\contentsline {paragraph}{}{15}{section*.93}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces State-decomposition into given number of subspaces\relax }}{16}{algocf.95}\protected@file@percent }
\newlabel{algo:threshold}{{2}{16}{}{algocf.95}{}}
\citation{noauthor_cloud_nodate}
\citation{keras}
\citation{noauthor_tensorflow_nodate}
\citation{openai_gym_nodate}
\citation{noauthor_openai_nodate}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experimental method}{17}{chapter.96}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{17}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Tools}{17}{section.98}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Python}{17}{section*.99}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Google Colaboratory (Colab)}{17}{section*.100}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Keras}{17}{section*.102}\protected@file@percent }
\@writefile{brf}{\backcite{keras}{{17}{4.1}{section*.102}}}
\@writefile{brf}{\backcite{noauthor_tensorflow_nodate}{{17}{4.1}{section*.102}}}
\@writefile{brf}{\backcite{noauthor_cloud_nodate}{{17}{1}{section*.100}}}
\citation{noauthor_openai_nodate}
\citation{noauthor_openai_nodate}
\@writefile{toc}{\contentsline {paragraph}{OpenAI Gym}{18}{section*.103}\protected@file@percent }
\@writefile{brf}{\backcite{openai_gym_nodate}{{18}{4.1}{section*.103}}}
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{18}{4.1}{section*.103}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite  {noauthor_openai_nodate}.\relax }}{18}{figure.caption.104}\protected@file@percent }
\@writefile{brf}{\backcite{noauthor_openai_nodate}{{18}{4.1}{figure.caption.104}}}
\newlabel{fig:cartpole}{{4.1}{18}{The CartPole-v1 environment is one of the most well-known environments of the OpenAI Gym library in which the goal is to balance the cartpole while keeping it within the boundaries of the screen by applying a leftwards or a rightwards force at each time-step. Screenshot of \cite {noauthor_openai_nodate}.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Testing environments}{18}{section.105}\protected@file@percent }
\newlabel{sec:TaxiTraps}{{4.2}{18}{Testing environments}{section.105}{}}
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.109}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.114}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Original and modified 'Taxi' environments. The thick black lines represent the walls, while the dotted lines represent the "traps".\relax }}{20}{figure.caption.115}\protected@file@percent }
\newlabel{fig:taxi}{{4.2}{20}{Original and modified 'Taxi' environments. The thick black lines represent the walls, while the dotted lines represent the "traps".\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {"Taxi"}}}{20}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {"TaxiTraps"}}}{20}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {"Taxi2"}}}{20}{subfigure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.119}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 'Grid' environment. The dotted lines have no effect on the environment, they simply separate the grid positions part of 'triangle 1' and 'triangle 2'.\relax }}{21}{figure.caption.120}\protected@file@percent }
\newlabel{fig:grid}{{4.3}{21}{'Grid' environment. The dotted lines have no effect on the environment, they simply separate the grid positions part of 'triangle 1' and 'triangle 2'.\relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {paragraph}{}{21}{section*.121}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces State transition probabilities in the 'GridEps' environment.\relax }}{21}{table.caption.122}\protected@file@percent }
\newlabel{table:state-transitions-GridEps}{{4.1}{21}{State transition probabilities in the 'GridEps' environment.\relax }{table.caption.122}{}}
\@writefile{toc}{\contentsline {paragraph}{}{21}{section*.123}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{21}{section*.124}\protected@file@percent }
\citation{kingma_adam_2017}
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.125}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.126}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Benchmark DQN agent}{22}{section.127}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.128}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{22}{section*.129}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{23}{section*.130}\protected@file@percent }
\@writefile{brf}{\backcite{kingma_adam_2017}{{23}{4.3}{section*.130}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }}{23}{figure.caption.134}\protected@file@percent }
\newlabel{fig:DQN-network}{{4.4}{23}{The neural network used for Q-values approximation in the baseline DQN algorithm.\relax }{figure.caption.134}{}}
\@writefile{toc}{\contentsline {paragraph}{}{23}{section*.135}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Ensuring fair comparison}{23}{section.136}\protected@file@percent }
\newlabel{sec:fair-comparison}{{4.4}{23}{Ensuring fair comparison}{section.136}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Evaluating results}{25}{chapter.137}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{25}{Evaluating results}{chapter.137}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation method}{25}{section.138}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{25}{section*.139}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces An example of an 'average reward' vs 'samples' graph. The red line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }}{26}{figure.caption.140}\protected@file@percent }
\newlabel{fig:samples-graph}{{5.1}{26}{An example of an 'average reward' vs 'samples' graph. The red line indicates the length of the shortest trial. Moving to the right of the line, the quality of the graph decreases and the average reward counterintuitively decreases due to the bias of only "bad" trials having such a high sample count.\relax }{figure.caption.140}{}}
\@writefile{toc}{\contentsline {paragraph}{}{26}{section*.141}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Effect of state representations}{26}{section.142}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{26}{section*.143}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }}{28}{figure.caption.148}\protected@file@percent }
\newlabel{fig:effect-state-encoding}{{5.2}{28}{Effect of different state encoding methods on the performance of the baseline DQN agent in the 'Grid' environment.\relax }{figure.caption.148}{}}
\@writefile{toc}{\contentsline {paragraph}{}{28}{section*.149}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Effect of NN size}{28}{section.150}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }}{29}{figure.caption.151}\protected@file@percent }
\newlabel{fig:effect_NN_dimension}{{5.3}{29}{Performance of DQN with NNs of different sizes in the Taxi2 environment. 'medium2' has twice the number of trainable weights of 'medium'.\relax }{figure.caption.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Initial results}{29}{section.152}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }}{30}{figure.caption.153}\protected@file@percent }
\newlabel{fig:two_stage}{{5.4}{30}{Performance of the original two-stage state-decomposition method. The networks are combined at episode 100, where the rewards fall to 'untrained agent' levels and take long to convergence, not any faster than a DQN agent.\relax }{figure.caption.153}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}'DeltaSwitch'}{30}{section.154}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{30}{section*.155}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces 'DeltaSwitch' architecture with $\delta =0$. In this case, the weighted sum effectively acts as a switch, which selects the output of the network corresponding to the subspace of the input state.\relax }}{31}{figure.caption.157}\protected@file@percent }
\newlabel{fig:delta-switch}{{5.5}{31}{'DeltaSwitch' architecture with $\delta =0$. In this case, the weighted sum effectively acts as a switch, which selects the output of the network corresponding to the subspace of the input state.\relax }{figure.caption.157}{}}
\@writefile{toc}{\contentsline {paragraph}{}{31}{section*.158}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the 'Taxi2' environment.\relax }}{32}{figure.caption.159}\protected@file@percent }
\newlabel{fig:Taxi2-dqn-deltaSwitch}{{5.6}{32}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the 'Taxi2' environment.\relax }{figure.caption.159}{}}
\@writefile{toc}{\contentsline {paragraph}{}{32}{section*.160}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }}{33}{figure.caption.161}\protected@file@percent }
\newlabel{fig:gridNoWall-dqn-deltaSwitch}{{5.7}{33}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }{figure.caption.161}{}}
\@writefile{toc}{\contentsline {paragraph}{}{33}{section*.162}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }}{34}{figure.caption.163}\protected@file@percent }
\newlabel{fig:one-hot}{{5.8}{34}{Performance of DQN and 'DeltaSwitch' when the state is one-hot encoded.\relax }{figure.caption.163}{}}
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.164}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{34}{section*.165}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Comparison of DeltaSwitch with different $\delta $.\relax }}{35}{figure.caption.167}\protected@file@percent }
\newlabel{fig:gridNoWall-deltaSwitch-compareDelta}{{5.9}{35}{Comparison of DeltaSwitch with different $\delta $.\relax }{figure.caption.167}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Applying 'DeltaSwitch' to non-prefectly decomposable environment}{35}{subsection.168}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.169}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.171}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.172}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }}{36}{figure.caption.170}\protected@file@percent }
\newlabel{fig:deltaSwitch-GridEps}{{5.10}{36}{DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }{figure.caption.170}{}}
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.173}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Effect of using reduced encoding}{37}{subsection.174}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{37}{section*.175}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Effect of reducing the input size.\relax }}{38}{figure.caption.176}\protected@file@percent }
\newlabel{fig:reduced-effect}{{5.11}{38}{Effect of reducing the input size.\relax }{figure.caption.176}{}}
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.177}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Effect of wall}{38}{subsection.179}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.180}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{38}{section*.181}\protected@file@percent }
\citation{pan_survey_2010}
\citation{taylor_transfer_nodate}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }}{39}{figure.caption.182}\protected@file@percent }
\newlabel{fig:wall}{{5.12}{39}{Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }{figure.caption.182}{}}
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.6}A different approach based on transfer learning}{39}{section.184}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{39}{section*.185}\protected@file@percent }
\@writefile{brf}{\backcite{pan_survey_2010}{{39}{5.6}{section*.185}}}
\@writefile{brf}{\backcite{taylor_transfer_nodate}{{39}{5.6}{section*.185}}}
\@writefile{toc}{\contentsline {paragraph}{}{40}{section*.186}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Combining 'NN0' and 'NN1' using another NN.\relax }}{40}{figure.caption.187}\protected@file@percent }
\newlabel{fig:combined-network}{{5.13}{40}{Combining 'NN0' and 'NN1' using another NN.\relax }{figure.caption.187}{}}
\@writefile{toc}{\contentsline {paragraph}{}{40}{section*.188}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{40}{section*.190}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \tmspace  +\thickmuskip {.2777em}1\%$.\relax }}{41}{figure.caption.191}\protected@file@percent }
\newlabel{fig:learnSwitch1}{{5.14}{41}{Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \;1\%$.\relax }{figure.caption.191}{}}
\@writefile{toc}{\contentsline {paragraph}{}{41}{section*.192}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }}{42}{figure.caption.195}\protected@file@percent }
\newlabel{fig:initialisedLearnSwitch}{{5.15}{42}{Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }{figure.caption.195}{}}
\@writefile{toc}{\contentsline {paragraph}{}{42}{section*.196}\protected@file@percent }
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\citation{rusu_progressive_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }}{43}{figure.caption.199}\protected@file@percent }
\newlabel{fig:SARSA-progressive}{{5.16}{43}{Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }{figure.caption.199}{}}
\@writefile{toc}{\contentsline {paragraph}{}{43}{section*.200}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{43}{5.6}{section*.200}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Structure of progressive network when training the third task. Figure taken from \cite  {rusu_progressive_2016}.\relax }}{44}{figure.caption.202}\protected@file@percent }
\@writefile{brf}{\backcite{rusu_progressive_2016}{{44}{5.17}{figure.caption.202}}}
\newlabel{fig:progressive-3-tasks}{{5.17}{44}{Structure of progressive network when training the third task. Figure taken from \cite {rusu_progressive_2016}.\relax }{figure.caption.202}{}}
\@writefile{toc}{\contentsline {paragraph}{}{44}{section*.203}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the combining network itself. $h$ indicates hidden layers of the network.\relax }}{45}{figure.caption.204}\protected@file@percent }
\newlabel{fig:modified-progressive}{{5.18}{45}{Modified progressive neural network. The layers of the combining neural network receive as inputs the respective outputs of the previous layers of frozen 'NN0', frozen 'NN1' and the combining network itself. $h$ indicates hidden layers of the network.\relax }{figure.caption.204}{}}
\@writefile{toc}{\contentsline {paragraph}{}{45}{section*.205}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Techniques to learn the 'switch'}{45}{section.206}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{45}{section*.207}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{46}{section*.209}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{46}{section*.212}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Applicability of the decomposition method}{48}{chapter.213}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{48}{section*.214}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{48}{section*.215}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Allocation of resources problem for two interconnected data centres.\relax }}{49}{figure.caption.216}\protected@file@percent }
\newlabel{fig:data-centres}{{6.1}{49}{Allocation of resources problem for two interconnected data centres.\relax }{figure.caption.216}{}}
\@writefile{toc}{\contentsline {paragraph}{}{49}{section*.217}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{50}{section*.218}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{50}{section*.219}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Possible state-decomposition agent.\relax }}{50}{figure.caption.220}\protected@file@percent }
\newlabel{fig:data-centres-decomposition-agent}{{6.2}{50}{Possible state-decomposition agent.\relax }{figure.caption.220}{}}
\@writefile{toc}{\contentsline {paragraph}{}{50}{section*.221}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{51}{section*.222}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions and further work}{52}{chapter.223}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Key findings}{52}{section.224}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.225}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.226}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.227}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{52}{section*.228}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.229}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Discussion}{53}{section.230}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.231}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.232}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.233}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{53}{section*.234}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{54}{section*.235}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Further work}{54}{section.236}\protected@file@percent }
\newlabel{sec:extensions}{{7.3}{54}{Further work}{section.236}{}}
\@writefile{toc}{\contentsline {paragraph}{Finding the state-transition matrix}{54}{section*.237}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Compression and embeddings of states}{54}{section*.238}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to continuous state spaces}{54}{section*.239}\protected@file@percent }
\newlabel{sec:different-decompositions}{{7.3}{54}{Applying state-decomposition to continuous state spaces}{section*.239}{}}
\@writefile{toc}{\contentsline {paragraph}{Different types of decomposition}{54}{section*.240}\protected@file@percent }
\citation{simsek_identifying_2005}
\citation{menache_q-cutdynamic_2002}
\@writefile{toc}{\contentsline {paragraph}{Sharing information between sub-agents}{55}{section*.241}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces MDP composed of smaller subspaces of states connected by few but probable transitions.\relax }}{55}{figure.caption.242}\protected@file@percent }
\newlabel{fig:connected-states}{{7.1}{55}{MDP composed of smaller subspaces of states connected by few but probable transitions.\relax }{figure.caption.242}{}}
\@writefile{toc}{\contentsline {paragraph}{Using state-decomposition for automatic sub-goal discovery}{55}{section*.243}\protected@file@percent }
\@writefile{brf}{\backcite{simsek_identifying_2005}{{55}{7.3}{section*.243}}}
\@writefile{brf}{\backcite{menache_q-cutdynamic_2002}{{55}{7.3}{section*.243}}}
\bibstyle{plain}
\bibdata{bibliography/bibliography,bibliography/zotero}
\@writefile{toc}{\contentsline {paragraph}{Proving mathematical bounds}{56}{section*.244}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applying state-decomposition to policy gradient algorithms}{56}{section*.245}\protected@file@percent }
\bibcite{noauthor_cloud_nodate}{1}
\bibcite{noauthor_google_nodate}{2}
\bibcite{noauthor_markov_2021}{3}
\bibcite{noauthor_openai_nodate}{4}
\bibcite{noauthor_tensorflow_nodate}{5}
\bibcite{aggregationHierarchical}{6}
\bibcite{autonomousDriving}{7}
\bibcite{barto_recent_2003}{8}
\bibcite{bellman_dynamic_1966}{9}
\bibcite{stateAggregation}{10}
\bibcite{dietterich_hierarchical_1999}{11}
\bibcite{goos_q-learning_1999}{12}
\bibcite{worldModels}{13}
\bibcite{kingma_adam_2017}{14}
\bibcite{menache_q-cutdynamic_2002}{15}
\bibcite{dqn}{16}
\bibcite{mnih_human-level_2015}{17}
\bibcite{moerland_model-based_2020}{18}
\bibcite{openai_gym_nodate}{19}
\bibcite{pan_survey_2010}{20}
\bibcite{parr_reinforcement_nodate}{21}
\bibcite{NLP}{22}
\bibcite{stateActionEmbeddings}{23}
\bibcite{rusu_progressive_2016}{24}
\bibcite{sharma_what_2019}{25}
\bibcite{silver_mastering_2017}{26}
\bibcite{sutton_dyna_1991}{27}
\bibcite{sutton_barto_2018}{28}
\bibcite{sutton_between_1999}{29}
\bibcite{taylor_transfer_nodate}{30}
\bibcite{keras}{31}
\bibcite{van_hasselt_deep_2015}{32}
\bibcite{wang_dueling_nodate}{33}
\bibcite{watkins_q-learning_1992}{34}
\bibcite{watkins_1989}{35}
\bibcite{wiskunde_doubleq-learning_nodate}{36}
\bibcite{yu_reinforcement_2020}{37}
\bibcite{ServicePlacement}{38}
\bibcite{SDNSynchronisation}{39}
\bibcite{simsek_identifying_2005}{40}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Performance graphs}{60}{appendix.247}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{appendix-graphs}{{A}{60}{Performance graphs}{appendix.247}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Performance of DQN and 'DeltaSwitch' in 'GridEps2'.\relax }}{60}{figure.caption.248}\protected@file@percent }
\newlabel{fig:GridEps2}{{A.1}{60}{Performance of DQN and 'DeltaSwitch' in 'GridEps2'.\relax }{figure.caption.248}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Effect of different state encoding methods on the performance of the baseline DQNagent in the ’Grid’ environment.\relax }}{61}{figure.caption.249}\protected@file@percent }
\newlabel{fig:Encodings-sample}{{A.2}{61}{Effect of different state encoding methods on the performance of the baseline DQNagent in the ’Grid’ environment.\relax }{figure.caption.249}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Performance of DQN with NNs of different sizes in the Taxi2 environment. ’medium2’has twice the number of trainable weights of ’medium’.\relax }}{62}{figure.caption.250}\protected@file@percent }
\newlabel{fig:sizes-sample}{{A.3}{62}{Performance of DQN with NNs of different sizes in the Taxi2 environment. ’medium2’has twice the number of trainable weights of ’medium’.\relax }{figure.caption.250}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }}{62}{figure.caption.251}\protected@file@percent }
\newlabel{fig:gridNoWall-dqn-deltaSwitch-samples}{{A.4}{62}{Comparison of DQN and DeltaSwitch with $\delta =0$ in the Grid environment.\relax }{figure.caption.251}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Comparison of DeltaSwitch with different $\delta $.\relax }}{63}{figure.caption.252}\protected@file@percent }
\newlabel{fig:gridNoWall-deltaSwitch-compareDelta-samples}{{A.5}{63}{Comparison of DeltaSwitch with different $\delta $.\relax }{figure.caption.252}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.7}{\ignorespaces Effect of reducing the input size.\relax }}{63}{figure.caption.254}\protected@file@percent }
\newlabel{fig:reduced-effect-sample}{{A.7}{63}{Effect of reducing the input size.\relax }{figure.caption.254}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }}{64}{figure.caption.253}\protected@file@percent }
\newlabel{fig:deltaSwitch-GridEps-samples}{{A.6}{64}{DeltaSwitch vs DQN in 'GridEps' with $0 \leq \epsilon \leq 5\%$.\relax }{figure.caption.253}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.8}{\ignorespaces Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }}{65}{figure.caption.255}\protected@file@percent }
\newlabel{fig:wall-samples}{{A.8}{65}{Performance of DQN and DeltaSwitch with different decomposition in the 'Grid' environment with wall.\relax }{figure.caption.255}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.9}{\ignorespaces Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \tmspace  +\thickmuskip {.2777em}1\%$.\relax }}{66}{figure.caption.256}\protected@file@percent }
\newlabel{fig:learnSwitch1-samples}{{A.9}{66}{Performance of combining 'NN0' and 'NN1' using another NN that is also fed the current state as input in a 'GridEps' environment with $\epsilon =0\%, \;1\%$.\relax }{figure.caption.256}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.10}{\ignorespaces Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }}{67}{figure.caption.257}\protected@file@percent }
\newlabel{fig:initialisedLearnSwitch-samples}{{A.10}{67}{Performance of combining 'NN0' and 'NN1' with another NN when initialising the combined network to behave as the original 'DeltaSwitch'. Tested with different network sizes\relax }{figure.caption.257}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.11}{\ignorespaces Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }}{68}{figure.caption.258}\protected@file@percent }
\newlabel{fig:SARSA-progressive-samples}{{A.11}{68}{Comparison of using Expected SARSA after combining, progressive combined network and standard DQN.\relax }{figure.caption.258}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.12}{\ignorespaces Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }}{69}{figure.caption.259}\protected@file@percent }
\newlabel{fig:progressive-combining-simultaneous-samples}{{A.12}{69}{Performance of progressive network and combining network when 'NN0' and 'NN1' are not pre-trained. Standard DQN and DeltaSwitch are shown for comparison.\relax }{figure.caption.259}{}}
